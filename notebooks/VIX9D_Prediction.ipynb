{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIX9D Volatility Prediction using LSTM\n",
    "\n",
    "This notebook implements an LSTM model to predict the Cboe S&P 500 Index 9-Day Volatility Index (VIX9D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = '../data/VIX9D_History-SP500.csv'\n",
    "SEQ_LENGTH = 60\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "HIDDEN_SIZE = 50\n",
    "NUM_LAYERS = 2\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    \"\"\"\n",
    "    Load data from CSV file.\n",
    "    Args:\n",
    "        filepath (str): Path to the CSV file.\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded dataframe with parsed dates.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    # Strip whitespace from column names just in case\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Parse dates\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'], format='%m/%d/%Y')\n",
    "    df = df.sort_values('DATE').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "class VIXDataset(Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = torch.FloatTensor(sequences)\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.targets[idx]\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"\n",
    "    Create sequences for LSTM.\n",
    "    Args:\n",
    "        data (np.array): Scaled data (num_samples, num_features).\n",
    "        seq_length (int): Length of the sequence.\n",
    "    Returns:\n",
    "        np.array, np.array: Sequences (X) and Targets (y).\n",
    "    \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:(i + seq_length)]\n",
    "        y = data[i + seq_length] # Predict the next step\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "def preprocess_data(df, target_col='CLOSE', seq_length=60, train_split=0.8):\n",
    "    \"\"\"\n",
    "    Preprocess data: normalize and split.\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe.\n",
    "        target_col (str): Column to predict.\n",
    "        seq_length (int): Window size.\n",
    "        train_split (float): Split ratio.\n",
    "    Returns:\n",
    "        dict: Contains train_loader, val_loader, scaler, train/val datasets\n",
    "    \"\"\"\n",
    "    data = df[[target_col]].values\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    \n",
    "    X, y = create_sequences(scaled_data, seq_length)\n",
    "    \n",
    "    train_size = int(len(X) * train_split)\n",
    "    \n",
    "    X_train, X_val = X[:train_size], X[train_size:]\n",
    "    y_train, y_val = y[:train_size], y[train_size:]\n",
    "    \n",
    "    train_dataset = VIXDataset(X_train, y_train)\n",
    "    val_dataset = VIXDataset(X_val, y_val)\n",
    "    \n",
    "    return {\n",
    "        'train_dataset': train_dataset,\n",
    "        'val_dataset': val_dataset,\n",
    "        'scaler': scaler,\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_val': X_val,\n",
    "        'y_val': y_val\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=50, num_layers=2, output_size=1, dropout=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Take the output from the last time step\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "if not os.path.exists(FILEPATH):\n",
    "    print(f\"Error: File not found at {FILEPATH}\")\n",
    "else:\n",
    "    df = load_data(FILEPATH)\n",
    "    data_dict = preprocess_data(df, target_col='CLOSE', seq_length=SEQ_LENGTH)\n",
    "    \n",
    "    train_dataset = data_dict['train_dataset']\n",
    "    val_dataset = data_dict['val_dataset']\n",
    "    scaler = data_dict['scaler']\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Model Setup\n",
    "    model = LSTMModel(input_size=1, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, output_size=1)\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Training Loop\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                running_val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = running_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{EPOCHS}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), '../results/models/best_model.pth')\n",
    "    \n",
    "    print(\"Training complete. Best Val Loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Plotting training history\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Final Evaluation on Val Set\n",
    "    model.load_state_dict(torch.load('../results/models/best_model.pth', weights_only=True))\n",
    "    model.eval()\n",
    "    \n",
    "    # Get all val predictions\n",
    "    X_val = torch.FloatTensor(data_dict['X_val']).to(DEVICE)\n",
    "    y_val = data_dict['y_val']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = model(X_val).cpu().numpy()\n",
    "    \n",
    "    # Inverse transform\n",
    "    preds_actual = scaler.inverse_transform(preds)\n",
    "    actual_y = scaler.inverse_transform(y_val)\n",
    "    \n",
    "    # Plot Actual vs Predicted\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(actual_y, label='Actual VIX9D')\n",
    "    plt.plot(preds_actual, label='Predicted VIX9D')\n",
    "    plt.title('VIX9D Prediction (Validation Set)')\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('VIX9D Close Price')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}